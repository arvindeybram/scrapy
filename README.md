"# WebCrawling" 
"# scrapy" 

First you have to download just the tutorial folder

Install scrapy using "pip install Scrapy"

1) Using terminal go into the directory it is in

    cd Downloads/tutorial

2) Crawl the website using the code - scrapy crawl spidername since the name of the spider is quotes, you can type

    scrapy crawl quotes

3) You can manually open the tutorial folder and find that there is a file called "quotes-1.html" the quotes that were crawled will be in that 

Similarly, for executing that alexa.py file you have open tutorial/spiders and replace the quotes_spider.py with alexa.py
 
Use scrapy crawl alexa

This should have crawled Alexa and stored  the extracted urls into a file
